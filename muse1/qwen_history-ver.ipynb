{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 135863,
     "status": "ok",
     "timestamp": 1742972895503,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "cHeY12CMnJh8",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fc03948e-ae0f-49be-da3d-db32cec2ece8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers torch langchain peft bitsandbytes faiss-cpu langchain.community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7671,
     "status": "ok",
     "timestamp": 1742972903175,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "P6uMxKSfoBRs",
    "outputId": "6ac8f6bb-53f2-4668-c59c-105043fd7657",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9104,
     "status": "ok",
     "timestamp": 1742972912286,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "zkJLhRa6rKhy",
    "outputId": "194482c2-9a49-441f-eec4-5f1fca0bd9bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y torchvision\n",
    "!pip install -y torchvision --index-url https://download.pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22988,
     "status": "ok",
     "timestamp": 1742972935275,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "FYoYizbHFmwq",
    "outputId": "f832ce97-3899-4890-a837-fd65a189aa8e"
   },
   "outputs": [],
   "source": [
    "!pip install pandas langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1742972935713,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "oZ3_KRJxGQ8b",
    "outputId": "70d27a0e-0006-4837-af6a-b3d4e02d3bea"
   },
   "outputs": [],
   "source": [
    "!pip install -U numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 45982,
     "status": "ok",
     "timestamp": 1742972981696,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "1aMkIuv_eFWu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from langchain.schema.document import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c7d388affd44198e6f86754bd8e92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MUSE 모델 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Gwangwoon/muse\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"✅ MUSE 모델 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1742972985586,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "5JSfz7Hqpzh6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wikipedia 검색 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1️⃣ Wikipedia API 래퍼 인스턴스 생성\n",
    "wiki_api = WikipediaAPIWrapper(lang=\"ko\")  # ✅ 한국어 위키 검색 설정\n",
    "\n",
    "# ✅ 2️⃣ Wikipedia 검색 도구 설정\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=wiki_api)\n",
    "\n",
    "print(\"✅ Wikipedia 검색 설정 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1742972985587,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "vtx4VUiDp032"
   },
   "outputs": [],
   "source": [
    "# ✅ 1️⃣ 유사도 임계값 설정 (0.7 이상인 문서만 채택)\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "\n",
    "def filter_similar_docs(docs):\n",
    "    # ✅ Document 객체는 딕셔너리처럼 접근할 수 없기 때문에 getattr 사용\n",
    "    filtered_docs = [doc for doc in docs if getattr(doc, 'similarity', 1.0) >= SIMILARITY_THRESHOLD]\n",
    "    return filtered_docs if filtered_docs else \"🔹 해당 정보는 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "aborted",
     "timestamp": 1742972985587,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "Jsb4BSBBhFbM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS 벡터DB 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "# ✅ FAISS 벡터 DB 로드\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever  = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"✅ FAISS 벡터DB 로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "aborted",
     "timestamp": 1742972985588,
     "user": {
      "displayName": "이다인",
      "userId": "13742699775445288769"
     },
     "user_tz": -540
    },
    "id": "XftyrkGAhAWV"
   },
   "outputs": [],
   "source": [
    "# ✅ 시스템 프롬프트\n",
    "# system_prompt = \"\"\"\n",
    "# 당신은 AI 역사 전문가입니다.\n",
    "# 아래 참고사항을 기반으로 답변해주세요.\n",
    "# 1. 같은 말을 반복하지 마세요. 간결한 문장으로 답변 해주세요.\n",
    "# 2. **연관 정보**를 기반으로 답변해주세요.\n",
    "# 3. 연관 정보에 없거나 불확실한 정보는 **그런 정보에 대해서는 알 수 없습니다.** 라고 답하세요.\n",
    "# \"\"\".strip()\n",
    "chat_history = []\n",
    "system_prompt = \"\"\"\n",
    "너는 국립중앙박물관에서 일하는 지적이고 친절한 AI 도슨트야. \n",
    "관람객이 어떤 언어로 질문하든 자동으로 언어를 감지하고, 그 언어로 자연스럽고 정확하게 답변해. \n",
    "너는 AI라는 말을 하지 않고, 박물관의 실제 도슨트처럼 행동해야 해.\n",
    "\n",
    "답변 원칙:\n",
    "- 한국어로 답해\n",
    "- 중복된 표현 없이 핵심 정보는 단 한 번만 전달해.\n",
    "- 어색하거나 기계적인 말투는 피하고, 사람처럼 자연스럽고 따뜻한 말투를 사용해.\n",
    "- 질문의 의도를 먼저 파악하려 노력해. 짧거나 모호한 질문이라도 사용자가 무엇을 궁금해하는지 유추해봐.\n",
    "- 유물 설명 시, 관련된 역사적 배경, 제작 방식, 문화적 의미, 출토지 등을 간결히 설명해.\n",
    "- 질문이 불명확하면 먼저 명확히 해달라고 요청해.\n",
    "- 정보를 모를 경우, \"잘 알려지지 않았습니다\" 또는 \"확실하지 않습니다\" 등으로 정직하게 답변해.\n",
    "- 필요 시 관련 유물이나 시대 정보를 추가로 제안해.\n",
    "- 반복되거나 의미 없는 말은 절대 하지 마.\n",
    "- 답변은 RAG 기반으로 구성하며, 신뢰 가능한 출처나 링크가 있다면 함께 제공해.\n",
    "\n",
    "답변 형식:\n",
    "1. 간결하고 핵심적인 답변을 가장 먼저 제시\n",
    "2. 이어서 배경 정보 또는 관련 유물 설명\n",
    "3. 출처 제공(가능한 경우), 중복 문장 금지\n",
    "\n",
    "예시:\n",
    "[질문] 이 유물은 어떤 시대에 만들어졌나요?\n",
    "[답변] 이 유물은 고려 시대(918~1392년)에 제작된 청자로, 왕실에서 의례용으로 사용되었습니다. 강진 지역에서 출토되었으며, 특유의 푸른빛과 정교한 문양이 특징입니다.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_eng = \"\"\"\n",
    "You are a knowledgeable and friendly AI docent at the National Museum of Korea. \n",
    "You must detect the visitor's language automatically and respond fluently and accurately in that language. \n",
    "You must not mention that you are an AI and instead behave like a real museum guide.\n",
    "\n",
    "Answer Guidelines:\n",
    "- Please answer in English.\n",
    "- Deliver key information clearly and only once, avoiding repetition.\n",
    "- Speak in a warm, human-like, and natural tone—never robotic or awkward.\n",
    "- Try to understand the intent behind each question, even if it is short or vague.\n",
    "- When explaining artifacts, include historical background, production methods, cultural context, and excavation sites concisely.\n",
    "- If the question is unclear, ask the user to clarify before answering.\n",
    "- If the information is unknown, respond honestly: e.g., \"This is not well known\" or \"The details are unclear.\"\n",
    "- Suggest related artifacts or historical periods when appropriate.\n",
    "- Never repeat unnecessary phrases or filler words.\n",
    "- Build your answers based on RAG (Retrieval-Augmented Generation). If possible, provide credible sources or links.\n",
    "\n",
    "Answer Format:\n",
    "1. Present the concise and essential answer first\n",
    "2. Follow with contextual or background explanations\n",
    "3. Include sources if available, and avoid redundant sentences\n",
    "\n",
    "Examples:\n",
    "[Question] When was this artifact made?\n",
    "[Answer] This artifact is a celadon piece from the Goryeo Dynasty (918–1392), traditionally used in royal rituals. It was excavated from the Gangjin region and is known for its distinctive bluish-green glaze and intricate patterns.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_japan = \"\"\"\n",
    "あなたは国立中央博物館で働く、知的で親切なAIドーセントです。来館者がどの言語で質問しても、自動的に言語を判別し、その言語で自然かつ正確に答えてください。\n",
    "自分がAIであることは言わず、本物の博物館ガイドのように振る舞ってください。\n",
    "\n",
    "回答のルール：\n",
    "- 日本語で答えてください。\n",
    "- 情報は簡潔に、一度だけ伝え、繰り返さないでください。\n",
    "- 不自然な表現や機械的な言い回しは避け、温かく、親しみやすい口調を使ってください。\n",
    "- 質問の意図をまず理解しようとしてください。短い質問や曖昧な表現でも、来館者の意図を推測してみてください。\n",
    "- 遺物を説明する際は、その歴史的背景、製作方法、文化的な意味、出土場所などを簡潔に紹介してください。\n",
    "- 質問が不明確な場合は、まず内容を明確にしてもらうようお願いしてください。\n",
    "- 情報が不明な場合は、「よくわかっていません」や「詳細は不明です」など、正直に答えてください。\n",
    "- 必要に応じて関連する遺物や時代の情報を提案してください。\n",
    "- 無意味な繰り返しや決まり文句は絶対に避けてください。\n",
    "- 回答はRAG（検索拡張生成）に基づいて行い、信頼できる情報源やリンクがあれば一緒に提示してください。\n",
    "\n",
    "回答形式：\n",
    "1. まず、簡潔で重要な情報を先に述べる\n",
    "2. 次に、背景や関連情報を説明する\n",
    "3. 可能であれば情報源を提示し、重複表現は避ける\n",
    "\n",
    "例：\n",
    "［質問］この遺物はいつの時代に作られたものですか？\n",
    "［回答］この遺物は高麗時代（918～1392年）に制作された青磁で、王室の儀式に使われていたとされています。全羅南道の康津（カンジン）地域で出土しており、独特な青緑色の釉薬と精緻な文様が特徴です。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 채팅 히스토리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HISTORY_MESSAGES = 10  # 전체 메시지 개수 기준 (user + assistant 포함)\n",
    "chat_history = []\n",
    "\n",
    "def ask_question(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    filtered_docs = filter_similar_docs(docs)\n",
    "\n",
    "    if filtered_docs == \"🔹 해당 정보는 없습니다.\":\n",
    "        print(\"\\n🔹 해당 정보는 없습니다. 위키피디아 검색을 진행합니다.\")\n",
    "        return wikipedia_tool.run(query)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in filtered_docs])\n",
    "\n",
    "    # ✅ 전체 메시지 구성 (히스토리 포함)\n",
    "    # messages = [{\"role\": \"system\", \"content\": system_prompt}] + chat_history\n",
    "    # messages.append({\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": f\"연관 정보:\\n{context}\\n질문: {query}\\n답변:\"\n",
    "    # })\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages += chat_history  # 과거 대화 유지\n",
    "    messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"연관 정보:\\n{context}\\n\\n질문: {query}\\n답변:\"})\n",
    "\n",
    "    # ✅ Chat template 적용\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ assistant 이후 텍스트만 추출\n",
    "    if \"assistant\" in output_text:\n",
    "        answer = output_text.split(\"assistant\")[-1].strip()\n",
    "    else:\n",
    "        answer = output_text.strip()\n",
    "\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": query})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    # ✅ 히스토리 길이 제한 적용 (가장 오래된 것부터 제거)\n",
    "    if len(chat_history) > MAX_HISTORY_MESSAGES:\n",
    "        # 가장 오래된 메시지부터 제거 → 최신 MAX_HISTORY_MESSAGES만 유지\n",
    "        chat_history[:] = chat_history[-MAX_HISTORY_MESSAGES:]\n",
    "\n",
    "\n",
    "    print(\"\\n🔹 검색된 문서:\")\n",
    "    print(context)\n",
    "    \n",
    "    print(\"\\n🔹 AI 응답:\")\n",
    "    print(answer)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    \n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 질문하세요 (또는 '종료' 입력 시 종료):  겨울 산수 만든 작가 누구야\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 검색된 문서:\n",
      "겨울 산수 (冬景山水圖) - 김수철(金秀哲)은 조선 말기에 유행했던 이색적인 화풍을 구사한 화가로 새로운 감각을 추구하였다.\n",
      "가을 산수 (秋景山水圖) - 이한철(李漢喆(1812~ ?\n",
      "가을 산수 (金昌秀筆秋景山水圖 김창수 필 추경산수도) - 감창수(號 鶴山)는 생애와 활동 내역에 대해 현재까지 전해지는 기록이 거의 없는 화가이다.\n",
      "\n",
      "🔹 AI 응답:\n",
      "겨울 산수는 김수철이 그렸습니다. 김수철은 조선 말기 화가로 이색적인 화풍을 구사하여 새로운 감각을 추구하였습니다.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 질문하세요 (또는 '종료' 입력 시 종료):  내가 방금 물어본 작가가 누구였지?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 검색된 문서:\n",
      "채미도 (採薇圖) - 鄂彼晨?\n",
      "꽃과 새 (花鳥圖) - 화면 오른쪽 중간에 ‘丁亥冬墨?\n",
      "옥계집 목판 (玉溪集木板) - 『옥계집』은 조선 명종 때의 문신 노진(盧?\n",
      "\n",
      "🔹 AI 응답:\n",
      "김수철이었습니다. 그는 조선 말기 화가로 독특한 화풍으로 유명합니다. 겨울 산수와 연관된 다른 작품으로는 채미도와 꽃과 새 등이 있습니다.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 질문하세요 (또는 '종료' 입력 시 종료):  tell me kimsuchul's art work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 검색된 문서:\n",
      "채미도 (採薇圖) - 鄂彼晨?\n",
      "채미도 (採薇圖) - 偕我小姑 薄言採?\n",
      "李士慶肖像 - *金夢虎書一点있음.\n",
      "\n",
      "🔹 AI 응답:\n",
      "김수철의 작품으로는 겨울 산수와 채미도가 있습니다. 채미도는 '채미'라는 주제로 그린 것으로 '채미'는 봄이 가고 여름이 올 때 꽃이 피지 않는 산초를 의미합니다. 이 작품에서는 산초를 그린 것이 아니라 봄이 가고 여름이 올 때 꽃이 피지 않는 산초를 표현한 것입니다. 또한 그의 대표작인 겨울 산수는 강진에서 출토된 고려시대의 청자로 왕실에서 의례용으로 사용된 것으로 유명합니다.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 질문하세요 (또는 '종료' 입력 시 종료):  겨울 산수 작품의 이미지 url을 줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 검색된 문서:\n",
      "겨울 산수 (冬景山水圖) - 이 작품에서는 간략한 필치와 단순한 형태 엷지만 선명한 색채가 두드러진다.\n",
      "겨울 산수 (冬景山水圖) - 온통 먹빛인 가운데 임포가 머물고 있는 집과 임포의 옷색은 붉은색이며 다리 건너 그를 찾아오는 이의 옷은 푸른색으로 서로 산뜻한 대비를 이룬다.\n",
      "가을 산수 (秋景山水圖) - 이한철(李漢喆(1812~ ?\n",
      "\n",
      "🔹 AI 응답:\n",
      "국립중앙박물관 소장의 겨울 산수는 강진에서 출토된 고려시대의 청자로 왕실에서 의례용으로 사용된 것으로 유명합니다. 이 작품에서는 간략한 필치와 단순한 형태 엷지만 선명한 색채가 두드러지고 있습니다. 온통 먹빛인 가운데 임포가 머물고 있는 집과 임포의 옷색은 붉은색이며 다리 건너 그를 찾아오는 이의 옷은 푸른색으로 서로 산뜻한 대비를 이루고 있습니다.\n",
      "\n",
      "이런 겨울 산수의 모습을 보시려면 아래의 링크를 클릭해 주세요.\n",
      "![겨울 산수](http://ncrmuseum.net/ex07/ex07_04_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01_01\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 질문하세요 (또는 '종료' 입력 시 종료):  종료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋 도슨트와의 대화를 종료합니다. 다음에 또 만나요!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"💬 질문하세요 (또는 '종료' 입력 시 종료): \")\n",
    "    if user_input.lower() in [\"종료\", \"exit\", \"quit\"]:\n",
    "        print(\"👋 도슨트와의 대화를 종료합니다. 다음에 또 만나요!\")\n",
    "        break\n",
    "    ask_question(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
